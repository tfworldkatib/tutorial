<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Hyperparameter tuning for TensorFlow using Katib and Kubeflow</title>
        
        <meta name="robots" content="noindex" />
        

        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" rel="stylesheet" type="text/css">
        <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro:500" rel="stylesheet" type="text/css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        

        
    </head>
    <body class="light">
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            document.body.className = theme;
            document.querySelector('html').className = theme + ' js';
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li><a href="prereqs/prereqs.html"><strong aria-hidden="true">1.</strong> Setup Prerequisites</a></li><li><ol class="section"><li><a href="prereqs/vagrant.html"><strong aria-hidden="true">1.1.</strong> Install Vagrant</a></li><li><a href="prereqs/vb.html"><strong aria-hidden="true">1.2.</strong> Install Virtualbox</a></li><li><a href="prereqs/download.html"><strong aria-hidden="true">1.3.</strong> Download Virtualbox VM</a></li></ol></li><li><a href="kubernetes/setup.html"><strong aria-hidden="true">2.</strong> Setup Kubernetes</a></li><li><ol class="section"><li><a href="kubernetes/k8s.html"><strong aria-hidden="true">2.1.</strong> Configure Persistent Storage</a></li><li><a href="kubernetes/architecture.html"><strong aria-hidden="true">2.2.</strong> Kubernetes Architecture</a></li></ol></li><li><a href="katib/katib.html"><strong aria-hidden="true">3.</strong> Katib</a></li><li><ol class="section"><li><a href="katib/install.html"><strong aria-hidden="true">3.1.</strong> Installation</a></li><li><a href="katib/hptuning.html"><strong aria-hidden="true">3.2.</strong> Hyperparameter Tuning</a></li><li><ol class="section"><li><a href="katib/random.html"><strong aria-hidden="true">3.2.1.</strong> Random Search</a></li><li><a href="katib/grid.html"><strong aria-hidden="true">3.2.2.</strong> Grid Search</a></li><li><a href="katib/bayesian.html"><strong aria-hidden="true">3.2.3.</strong> Bayesian Optimization</a></li></ol></li><li><a href="katib/automl.html"><strong aria-hidden="true">3.3.</strong> (Optional) AutoML Intuition</a></li></ol></li><li><a href="kubeflow/kubeflow.html"><strong aria-hidden="true">4.</strong> Kubeflow</a></li><li><ol class="section"><li><a href="kubeflow/install.html"><strong aria-hidden="true">4.1.</strong> Installation</a></li><li><a href="kubeflow/pipelines.html"><strong aria-hidden="true">4.2.</strong> Pipelines</a></li></ol></li><li><a href="cleanup/cleanup.html"><strong aria-hidden="true">5.</strong> Cleanup</a></li><li><a href="references/index.html"><strong aria-hidden="true">6.</strong> References</a></li><li class="spacer"></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar" class="menu-bar">
                    <div id="menu-bar-sticky-container">
                        <div class="left-buttons">
                            <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                                <i class="fa fa-bars"></i>
                            </button>
                            <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                                <i class="fa fa-paint-brush"></i>
                            </button>
                            <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                                <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                                <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                                <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                                <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                                <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                            </ul>
                            
                            <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                                <i class="fa fa-search"></i>
                            </button>
                            
                        </div>

                        <h1 class="menu-title">Hyperparameter tuning for TensorFlow using Katib and Kubeflow</h1>

                        <div class="right-buttons">
                            <a href="print.html" title="Print this book" aria-label="Print this book">
                                <i id="print-button" class="fa fa-print"></i>
                            </a>
                            
                        </div>
                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" name="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1><a class="header" href="#setup-prerequisites" id="setup-prerequisites">Setup Prerequisites</a></h1>
<h3><a class="header" href="#goals" id="goals">Goals</a></h3>
<p>In this section we will setup a single node Kubernetes cluster.</p>
<p><code>You can skip this section if you have an existing Kubernetes cluster with a dynamic volume provisioner.</code></p>
<h3><a class="header" href="#overview" id="overview">Overview</a></h3>
<p><a href="https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/">Kubernetes (K8s)</a> is an open-source system for automating deployment, scaling, and management of containerized applications. For this tutorial we will setup a single node Kubernetes cluster using <a href="https://www.vagrantup.com/downloads.html">Vagrant</a> and <a href="https://www.virtualbox.org/wiki/Downloads">VirtualBox</a>.</p>
<h3><a class="header" href="#prerequisites" id="prerequisites">Prerequisites</a></h3>
<ul>
<li>Vagrant 2.2.5 or later</li>
<li>VirtualBox 6.0.14 or later</li>
<li>Laptop or server with at least 4 CPU cores and 16 Gig of RAM</li>
</ul>
<h1><a class="header" href="#install-vagrant" id="install-vagrant">Install Vagrant</a></h1>
<p>Follow the instructions <a href="https://www.vagrantup.com/downloads.html">here</a> to install Vagrant for your operating system.</p>
<h1><a class="header" href="#install-virtual-box" id="install-virtual-box">Install Virtual Box</a></h1>
<p>Follow the instructions <a href="https://www.virtualbox.org/wiki/Downloads">here</a> to install VirtualBox for your operating system.</p>
<h1><a class="header" href="#download-virtualbox-image" id="download-virtualbox-image">Download Virtualbox Image</a></h1>
<p>Clone the repository for this workshop.</p>
<pre><code class="language-console">git clone https://github.com/tfworldkatib/tutorial
cd tutorial
</code></pre>
<p>Start the Vagrant virtual machine that we will use </p>
<pre><code class="language-console">vagrant up
</code></pre>
<details>
<summary>
 Sample Output
 </summary>
vagrant up
Bringing machine 'default' up with 'virtualbox' provider...
==> default: Importing base box 'minikatib/tfworld'...
==> default: Matching MAC address for NAT networking...
==> default: Checking if box 'minikatib/tfworld' version '0.2.0' is up to date...
==> default: Setting the name of the VM: tfworld_default_1571554286050_26802
==> default: Fixed port collision for 22 => 2222. Now on port 2200.
==> default: Clearing any previously set network interfaces...
==> default: Preparing network interfaces based on configuration...
    default: Adapter 1: nat
==> default: Forwarding ports...
    default: 31230 (guest) => 31230 (host) (adapter 1)
    default: 22 (guest) => 2200 (host) (adapter 1)
==> default: Running 'pre-boot' VM customizations...
==> default: Booting VM...
==> default: Waiting for machine to boot. This may take a few minutes...
    default: SSH address: 127.0.0.1:2200
    default: SSH username: vagrant
    default: SSH auth method: private key
==> default: Machine booted and ready!
==> default: Checking for guest additions in VM...
==> default: Mounting shared folders...
    default: /vagrant => /Users/neelimam/minikatib/t3/tfworld
==> default: Running provisioner: shell...
    default: Running: inline script
    default: [init] Using Kubernetes version: v1.14.8
    default: [preflight] Running pre-flight checks
    default: 	[WARNING Service-Docker]: docker service is not enabled, please run 'systemctl enable docker.service'
    default: 	[WARNING IsDockerSystemdCheck]: detected "cgroupfs" as the Docker cgroup driver. The recommended driver is "systemd". Please follow the guide at https://kubernetes.io/docs/setup/cri/
    default: [preflight] Pulling images required for setting up a Kubernetes cluster
    default: [preflight] This might take a minute or two, depending on the speed of your internet connection
    default: [preflight] You can also perform this action in beforehand using 'kubeadm config images pull'
    default: [kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"
    default: [kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"
    default: [kubelet-start] Activating the kubelet service
    default: [certs] Using certificateDir folder "/etc/kubernetes/pki"
    default: [certs] Generating "ca" certificate and key
    default: [certs] Generating "apiserver" certificate and key
    default: [certs] apiserver serving cert is signed for DNS names [katib kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 10.0.2.15]
    default: [certs] Generating "apiserver-kubelet-client" certificate and key
    default: [certs] Generating "front-proxy-ca" certificate and key
    default: [certs] Generating "front-proxy-client" certificate and key
    default: [certs] Generating "etcd/ca" certificate and key
    default: [certs] Generating "etcd/server" certificate and key
    default: [certs] etcd/server serving cert is signed for DNS names [katib localhost] and IPs [10.0.2.15 127.0.0.1 ::1]
    default: [certs] Generating "etcd/peer" certificate and key
    default: [certs] etcd/peer serving cert is signed for DNS names [katib localhost] and IPs [10.0.2.15 127.0.0.1 ::1]
    default: [certs] Generating "etcd/healthcheck-client" certificate and key
    default: [certs] Generating "apiserver-etcd-client" certificate and key
    default: [certs] Generating "sa" key and public key
    default: [kubeconfig] Using kubeconfig folder "/etc/kubernetes"
    default: [kubeconfig] Writing "admin.conf" kubeconfig file
    default: [kubeconfig] Writing "kubelet.conf" kubeconfig file
    default: [kubeconfig] Writing "controller-manager.conf" kubeconfig file
    default: [kubeconfig] Writing "scheduler.conf" kubeconfig file
    default: [control-plane] Using manifest folder "/etc/kubernetes/manifests"
    default: [control-plane] Creating static Pod manifest for "kube-apiserver"
    default: [control-plane] Creating static Pod manifest for "kube-controller-manager"
    default: [control-plane] Creating static Pod manifest for "kube-scheduler"
    default: [etcd] Creating static Pod manifest for local etcd in "/etc/kubernetes/manifests"
    default: [wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory "/etc/kubernetes/manifests". This can take up to 4m0s
    default: [apiclient] All control plane components are healthy after 36.003972 seconds
    default: [upload-config] storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace
    default: [kubelet] Creating a ConfigMap "kubelet-config-1.14" in namespace kube-system with the configuration for the kubelets in the cluster
    default: [upload-certs] Skipping phase. Please see --experimental-upload-certs
    default: [mark-control-plane] Marking the node katib as control-plane by adding the label "node-role.kubernetes.io/master=''"
    default: [mark-control-plane] Marking the node katib as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]
    default: [bootstrap-token] Using token: 6cvjk2.7kwbwb0oedxmmxnf
    default: [bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
    default: [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
    default: [bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
    default: [bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
    default: [bootstrap-token] creating the "cluster-info" ConfigMap in the "kube-public" namespace
    default: [addons] Applied essential addon: CoreDNS
    default: [addons] Applied essential addon: kube-proxy
    default:
    default: Your Kubernetes control-plane has initialized successfully!
    default:
    default: To start using your cluster, you need to run the following as a regular user:
    default:
    default:   mkdir -p $HOME/.kube
    default:   sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
    default:   sudo chown $(id -u):$(id -g) $HOME/.kube/config
    default:
    default: You should now deploy a pod network to the cluster.
    default: Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
    default:   https://kubernetes.io/docs/concepts/cluster-administration/addons/
    default:
    default: Then you can join any number of worker nodes by running the following on each as root:
    default:
    default: kubeadm join 10.0.2.15:6443 --token 6cvjk2.7kwbwb0oedxmmxnf \
    default:     --discovery-token-ca-cert-hash sha256:081c1fe5d9e42a8d2c85ffc7465a3b606d8ae90e7511861cb7eeba3397a7e3f5
    default: node/katib untainted
    default: configmap/kube-router-cfg created
    default: daemonset.apps/kube-router created
    default: serviceaccount/kube-router created
    default: clusterrole.rbac.authorization.k8s.io/kube-router created
    default: clusterrolebinding.rbac.authorization.k8s.io/kube-router created
    default: persistentvolume/data-kf-nfs-server-provisioner-0 created
</details>
<p><code>vagrant up</code> downloads the Virtual Box image for this tutorial and powers it on.
This may take 15-20 minutes and at the end of it you will have a single node Kubernetes cluster.</p>
<h1><a class="header" href="#setup-kubernetes" id="setup-kubernetes">Setup Kubernetes</a></h1>
<h3><a class="header" href="#goals-1" id="goals-1">Goals</a></h3>
<p>In this section we will configure the single node Kubernetes cluster to support persistent storage.</p>
<p><code>You can skip this section if you have an existing Kubernetes cluster with a dynamic volume provisioner.</code></p>
<p>Troubleshooting:</p>
<p>If you see an SSL error during vagrant up, please add the following to <code>Vagrantfile</code> after line 11.</p>
<pre><code>config.vm.box_download_insecure = true
</code></pre>
<p>If you have an existing image that you were trying to download, you need to delete it.
Go to the tutorial folder and do the following:</p>
<pre><code>vagrant destroy
</code></pre>
<p>Add Virtual Box image using the USB box file.</p>
<pre><code>
vagrant box add --provider=virtualbox minikatib/tfworld package.box
</code></pre>
<h1><a class="header" href="#install-kubernetes" id="install-kubernetes">Install Kubernetes</a></h1>
<p>Login to the VM</p>
<pre><code>vagrant ssh
</code></pre>
<details>
<summary>
 Sample Output
 </summary>
Welcome to Ubuntu 18.04.2 LTS (GNU/Linux 4.15.0-51-generic x86_64)
<ul>
<li>Documentation:  https://help.ubuntu.com</li>
<li>Management:     https://landscape.canonical.com</li>
<li>Support:        https://ubuntu.com/advantage</li>
</ul>
<p>System information as of Sun Oct 20 06:53:33 UTC 2019</p>
<p>System load:  0.87               Users logged in:            0
Usage of /:   18.6% of 61.80GB   IP address for eth0:        10.0.2.15
Memory usage: 14%                IP address for docker0:     172.17.0.1
Swap usage:   0%                 IP address for kube-bridge: 192.168.0.1
Processes:    160</p>
<ul>
<li>
<p>Kata Containers are now fully integrated in Charmed Kubernetes 1.16!
Yes, charms take the Krazy out of K8s Kata Kluster Konstruction.</p>
<p>https://ubuntu.com/kubernetes/docs/release-notes</p>
</li>
</ul>
<p>111 packages can be updated.
60 updates are security updates.</p>
<p>Last login: Sun Oct 20 03:54:17 2019 from 10.0.2.2</p>
</details>
<p>Kubernetes has been started during VM provisioning. You can confirm this as follows.</p>
<pre><code class="language-console">kubectl get nodes
</code></pre>
<details>
<summary>
 Sample Output
 </summary>
 NAME    STATUS   ROLES    AGE     VERSION
katib   Ready    master   2m15s   v1.14.8
</details>
<p>Start helm and install NFS helm chart. This provides dynamic provisioning for Kubernetes workloads.</p>
<pre><code>cd $HOME/tfworld/setup/k8s-config/
./start-helm.sh
</code></pre>
<p>This will take a couple of minutes.</p>
<details>
<summary>
 Sample Output
 </summary>
serviceaccount/tiller created
clusterrolebinding.rbac.authorization.k8s.io/tiller created
Creating /home/vagrant/.helm
Creating /home/vagrant/.helm/repository
Creating /home/vagrant/.helm/repository/cache
Creating /home/vagrant/.helm/repository/local
Creating /home/vagrant/.helm/plugins
Creating /home/vagrant/.helm/starters
Creating /home/vagrant/.helm/cache/archive
Creating /home/vagrant/.helm/repository/repositories.yaml
Adding stable repo with URL: https://kubernetes-charts.storage.googleapis.com
Adding local repo with URL: http://127.0.0.1:8879/charts
$HELM_HOME has been configured at /home/vagrant/.helm.
<p>Tiller (the Helm server-side component) has been installed into your Kubernetes Cluster.</p>
<p>Please note: by default, Tiller is deployed with an insecure 'allow unauthenticated users' policy.
To prevent this, run <code>helm init</code> with the --tiller-tls-verify flag.
For more information on securing your installation see: https://docs.helm.sh/using_helm/#securing-your-helm-installation
Hang tight while we grab the latest from your chart repositories...
...Skip local chart repository
...Successfully got an update from the &quot;stable&quot; chart repository
Update Complete.
NAME:   kf
LAST DEPLOYED: Sun Oct 20 06:56:39 2019
NAMESPACE: kube-system
STATUS: DEPLOYED</p>
<p>RESOURCES:
==&gt; v1/ClusterRole
NAME                       AGE
kf-nfs-server-provisioner  1s</p>
<p>==&gt; v1/ClusterRoleBinding
NAME                       AGE
kf-nfs-server-provisioner  1s</p>
<p>==&gt; v1/Pod(related)
NAME                         READY  STATUS   RESTARTS  AGE
kf-nfs-server-provisioner-0  0/1    Pending  0         1s</p>
<p>==&gt; v1/Service
NAME                       TYPE       CLUSTER-IP     EXTERNAL-IP  PORT(S)                                 AGE
kf-nfs-server-provisioner  ClusterIP  10.100.45.158  <none>       2049/TCP,20048/TCP,51413/TCP,51413/UDP  1s</p>
<p>==&gt; v1/ServiceAccount
NAME                       SECRETS  AGE
kf-nfs-server-provisioner  1        1s</p>
<p>==&gt; v1/StorageClass
NAME  PROVISIONER                              AGE
nfs   cluster.local/kf-nfs-server-provisioner  1s</p>
<p>==&gt; v1beta2/StatefulSet
NAME                       READY  AGE
kf-nfs-server-provisioner  0/1    1s</p>
<p>NOTES:
The NFS Provisioner service has now been installed.</p>
<p>A storage class named 'nfs' has now been created
and is available to provision dynamic volumes.</p>
<p>You can use this storageclass by creating a <code>PersistentVolumeClaim</code> with the
correct storageClassName attribute. For example:</p>
<pre><code>---
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: test-dynamic-volume-claim
spec:
  storageClassName: &quot;nfs&quot;
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 100Mi
</code></pre>
</details>
<p><strong>Congratulations!</strong> Now you have a single node Kubernetes cluster on your laptop. The magic of Kubernetes allows you to run your workloads on this tiny Kubernetes cluster identical to how you would on your production cluster in your datacenter or in a cloud.</p>
<h1><a class="header" href="#kubernetes-architecture" id="kubernetes-architecture">Kubernetes Architecture</a></h1>
<p>A Kubernetes cluster consists of some master components and some worker components. 
In a single node Kubernetes cluster, master and worker components may run on the same node.
In a production Kubernetes cluster you typically have one or more master nodes and many worker nodes.</p>
<p><img src="kubernetes/../images/kubernetes.png" alt="Kubernetes Architecture" /></p>
<p>Kubernetes API server is the primary interface to an end user - either using kubectl or client-go or an application using the Kubernetes API.</p>
<p>Kubernetes API server manages versioned resources. You can add new resource types to a Kubernetes API server.
Pods, Deployments, Services are examples on built in resources or <code>Kinds</code>. In this tutorial we will be working with custom resources like <code>Experiments</code>, <code>Suggestions</code> and <code>Trials</code>. Resources are grouped together into API groups and are versioned.</p>
<p>You can explore the API groups and resources available on your Kubernetes cluster as follows.</p>
<pre><code class="language-console">kubectl api-versions
</code></pre>
<details>
<summary>
 Sample Output
 </summary>
 admissionregistration.k8s.io/v1beta1
apiextensions.k8s.io/v1beta1
apiregistration.k8s.io/v1
apiregistration.k8s.io/v1beta1
apps/v1
apps/v1beta1
apps/v1beta2
authentication.k8s.io/v1
authentication.k8s.io/v1beta1
authorization.k8s.io/v1
authorization.k8s.io/v1beta1
autoscaling/v1
autoscaling/v2beta1
autoscaling/v2beta2
batch/v1
batch/v1beta1
certificates.k8s.io/v1beta1
coordination.k8s.io/v1
coordination.k8s.io/v1beta1
events.k8s.io/v1beta1
extensions/v1beta1
kubeflow.org/v1
kubeflow.org/v1alpha3
networking.k8s.io/v1
networking.k8s.io/v1beta1
node.k8s.io/v1beta1
policy/v1beta1
rbac.authorization.k8s.io/v1
rbac.authorization.k8s.io/v1beta1
scheduling.k8s.io/v1
scheduling.k8s.io/v1beta1
storage.k8s.io/v1
storage.k8s.io/v1beta1
v1
 </details>
<p>You can see the available Kubernetes resources(<code>Kinds</code>) as follows.</p>
<pre><code class="language-console">kubectl api-resources
</code></pre>
<details>
<summary>
 Sample Output
 </summary>
 NAME                              SHORTNAMES   APIGROUP                       NAMESPACED   KIND
bindings                                                                      true         Binding
componentstatuses                 cs                                          false        ComponentStatus
configmaps                        cm                                          true         ConfigMap
endpoints                         ep                                          true         Endpoints
events                            ev                                          true         Event
limitranges                       limits                                      true         LimitRange
namespaces                        ns                                          false        Namespace
nodes                             no                                          false        Node
persistentvolumeclaims            pvc                                         true         PersistentVolumeClaim
persistentvolumes                 pv                                          false        PersistentVolume
pods                              po                                          true         Pod
podtemplates                                                                  true         PodTemplate
replicationcontrollers            rc                                          true         ReplicationController
resourcequotas                    quota                                       true         ResourceQuota
secrets                                                                       true         Secret
serviceaccounts                   sa                                          true         ServiceAccount
services                          svc                                         true         Service
mutatingwebhookconfigurations                  admissionregistration.k8s.io   false        MutatingWebhookConfiguration
validatingwebhookconfigurations                admissionregistration.k8s.io   false        ValidatingWebhookConfiguration
customresourcedefinitions         crd,crds     apiextensions.k8s.io           false        CustomResourceDefinition
apiservices                                    apiregistration.k8s.io         false        APIService
controllerrevisions                            apps                           true         ControllerRevision
daemonsets                        ds           apps                           true         DaemonSet
deployments                       deploy       apps                           true         Deployment
replicasets                       rs           apps                           true         ReplicaSet
statefulsets                      sts          apps                           true         StatefulSet
tokenreviews                                   authentication.k8s.io          false        TokenReview
localsubjectaccessreviews                      authorization.k8s.io           true         LocalSubjectAccessReview
selfsubjectaccessreviews                       authorization.k8s.io           false        SelfSubjectAccessReview
selfsubjectrulesreviews                        authorization.k8s.io           false        SelfSubjectRulesReview
subjectaccessreviews                           authorization.k8s.io           false        SubjectAccessReview
horizontalpodautoscalers          hpa          autoscaling                    true         HorizontalPodAutoscaler
cronjobs                          cj           batch                          true         CronJob
jobs                                           batch                          true         Job
certificatesigningrequests        csr          certificates.k8s.io            false        CertificateSigningRequest
leases                                         coordination.k8s.io            true         Lease
events                            ev           events.k8s.io                  true         Event
daemonsets                        ds           extensions                     true         DaemonSet
deployments                       deploy       extensions                     true         Deployment
ingresses                         ing          extensions                     true         Ingress
networkpolicies                   netpol       extensions                     true         NetworkPolicy
podsecuritypolicies               psp          extensions                     false        PodSecurityPolicy
replicasets                       rs           extensions                     true         ReplicaSet
experiments                                    kubeflow.org                   true         Experiment
pytorchjobs                                    kubeflow.org                   true         PyTorchJob
suggestions                                    kubeflow.org                   true         Suggestion
tfjobs                                         kubeflow.org                   true         TFJob
trials                                         kubeflow.org                   true         Trial
ingresses                         ing          networking.k8s.io              true         Ingress
networkpolicies                   netpol       networking.k8s.io              true         NetworkPolicy
runtimeclasses                                 node.k8s.io                    false        RuntimeClass
poddisruptionbudgets              pdb          policy                         true         PodDisruptionBudget
podsecuritypolicies               psp          policy                         false        PodSecurityPolicy
clusterrolebindings                            rbac.authorization.k8s.io      false        ClusterRoleBinding
clusterroles                                   rbac.authorization.k8s.io      false        ClusterRole
rolebindings                                   rbac.authorization.k8s.io      true         RoleBinding
roles                                          rbac.authorization.k8s.io      true         Role
priorityclasses                   pc           scheduling.k8s.io              false        PriorityClass
csidrivers                                     storage.k8s.io                 false        CSIDriver
csinodes                                       storage.k8s.io                 false        CSINode
storageclasses                    sc           storage.k8s.io                 false        StorageClass
volumeattachments                              storage.k8s.io                 false        VolumeAttachment
</details>
<h3><a class="header" href="#pod" id="pod">Pod</a></h3>
<p>Specification for a Kubernetes resource  can be done via yaml file. Kubernetes manages pods instead of containers. A pod can contain one or more containers. Containers in a pod share resources and common local network. As we will see during Katib section of the tutorial, Katib injects a metrics container to the model training pod. Here is a yaml file to run mnist example as a pod.  The max_steps is set to 1 to speed-up running the mnist example.</p>
<details>
<summary>
Mnist pod example
</summary>
<pre><code class="language-yaml">apiVersion: v1
kind: Pod
metadata:
  name: mnistpod
spec:
  containers:
  - name: mnist
    image: gcr.io/kubeflow-ci/tf-mnist-with-summaries:1.0
    command:
    - &quot;python&quot;
    - &quot;/var/tf_mnist/mnist_with_summaries.py&quot;
    - &quot;--max_steps=1&quot;        
    - &quot;--batch_size=2&quot;        
  restartPolicy: Never
</code></pre>
</details>
<pre><code class="language-console">cd $HOME
git clone https://github.com/tfworldkatib/tutorial.git
cd $HOME/tutorial/examples
kubectl apply -f mnistpod.yaml
</code></pre>
<details>
<summary>
 Sample Output
 </summary>
pod/mnistpod created
</details>
<p>Check that the <code>Pod</code> <strong>mnistpod</strong> has started.</p>
<pre><code class="language-console">kubectl get pods
</code></pre>
<details>
<summary>
 Sample Output
 </summary>
NAME            STATUS    AGE
mnistpod       Running    2s
</details> 
<p>Check the logs of the <code>Pod</code> <strong>mnistpod</strong></p>
<pre><code class="language-console">kubectl logs -f mnistpod 
</code></pre>
<details>
<summary>
 Sample Output
 </summary>
WARNING:tensorflow:From /var/tf_mnist/mnist_with_summaries.py:39: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please use urllib or similar directly.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: __init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2019-10-29 01:42:17.348035: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.
Extracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz
Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.
Extracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz
Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.
Extracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz
Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.
Extracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz
Accuracy at step 0: 0.1005
</details>
<p>Notice the Accuracy output from the <strong>mnistpod</strong>.  This will be used by Katib to find accuracy results from a given hyperparameter set.</p>
<p>Delete the <code>Pod</code> <strong>mnistpod</strong></p>
<pre><code class="language-console">kubectl delete -f mnistpod.yaml
</code></pre>
<h3><a class="header" href="#crd-custom-resource-definition" id="crd-custom-resource-definition">CRD (Custom Resource Definition)</a></h3>
<p>Kubernetes supports <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/extend-cluster/">various</a> types of extension capabilities at all layers, starting with the API server, scheduler, controllers all the way to the kubelet. One of the common patterns used to add new resources and capabilities to the Kubernetes API server is called the Operator Pattern. This consists of creating a custom resource(<code>Kind</code>) and a controller that manages this custom resource.
Kubeflow and Katib use this extensively. This allows Kubeflow and Katib to be integrated with Kubernetes. You can manage and interact with Kubeflow and Katib components just as you interact with any other Kubernetes component!</p>
<p><img src="kubernetes/../images/operator.png" alt="Kubernetes Extensibility" /></p>
<p>You can see the available Kubernetes custom resource definitions as follows.</p>
<pre><code class="language-console">kubectl get crds
</code></pre>
<details>
<summary>
 Sample Output
 </summary>
 NAME                       CREATED AT
experiments.kubeflow.org   2019-10-26T21:00:25Z
pytorchjobs.kubeflow.org   2019-10-26T21:00:27Z
suggestions.kubeflow.org   2019-10-26T21:00:25Z
tfjobs.kubeflow.org        2019-10-26T21:00:27Z
trials.kubeflow.org        2019-10-26T21:00:25Z
</details>
<h1><a class="header" href="#katib" id="katib">Katib</a></h1>
<p>Katib is a scalable and extensible <code>Automatic Machine Learning</code>(AutoML) framework on Kubernetes. It supports Hyperparameter tuning and neural architecture search. It enables users to discover models that are as good as hand-crafted models, without having to go through the laborious process of manual configuration and iteration.</p>
<p>Katib organizes an optimization or neural architecture search as an <code>Experiment</code>. 
AutoML algorithms run in an interactive manner. An <code>Experiment</code> defines the search space, metrics target and maximum number of iterations. Katib searches iteratively in the search space to meet the metrics target or for the maximum number of iterations.
Katib supports two different mechanisms for AutoML - Hyperparameter Tuning and Neural Architecture Search.</p>
<p><img src="katib/../images/automl.png" alt="AutoML" /></p>
<h2><a class="header" href="#etymology" id="etymology">Etymology</a></h2>
<p>Katib stands for <code>secretary</code> in Arabic. As <code>Vizier</code> stands for a high official or a prime minister in Arabic, this project Katib is named in the honor of <a href="https://ai.google/research/pubs/pub46180">Vizier</a>.</p>
<h2><a class="header" href="#hyperparameter-tuning" id="hyperparameter-tuning">Hyperparameter Tuning</a></h2>
<p>Hyperparameter tuning finds the optimal hyperparameter vector for a given model architecture. In each iteration Katib uses a <code>Suggestion</code> algorithm to generate a candidate hyperparameter vector. The candidate hyperparameters are given to a <code>Trial</code> that provides training and validation services. The metrics collected from that trial are fed into the <code>Suggestion</code> algorithm to generate the candidate vector for the next iteration. This process continues till we reach the desired metric goal or the maximum number of iterations if complete.</p>
<p><img src="katib/../images/hpt.png" alt="Hyperparameter tuning" /></p>
<p>In this tutorial we will focus on Hyperparameter tuning.</p>
<h2><a class="header" href="#neural-architecture-search" id="neural-architecture-search">Neural Architecture Search</a></h2>
<p>Neural Architecture Search finds the optimal neural architecture for a given data set.</p>
<p><img src="katib/../images/katib.png" alt="Neural Architecture Search" /></p>
<h1><a class="header" href="#installation" id="installation">Installation</a></h1>
<p>Let us start with the install of Katib.</p>
<pre><code>cd $HOME
git clone https://github.com/tfworldkatib/tutorial.git
cd $HOME/tutorial/setup/katib-install
./deploy.sh
</code></pre>
<details>
<summary>
 Sample Output
 </summary>
 ```
 + kubectl apply -f v1alpha3
namespace/kubeflow created
+ kubectl apply -f v1alpha3/katib-controller
customresourcedefinition.apiextensions.k8s.io/experiments.kubeflow.org created
customresourcedefinition.apiextensions.k8s.io/suggestions.kubeflow.org created
customresourcedefinition.apiextensions.k8s.io/trials.kubeflow.org created
configmap/katib-config created
deployment.apps/katib-controller created
clusterrole.rbac.authorization.k8s.io/katib-controller created
serviceaccount/katib-controller created
clusterrolebinding.rbac.authorization.k8s.io/katib-controller created
secret/katib-controller created
service/katib-controller created
configmap/trial-template created
+ kubectl apply -f v1alpha3/manager
deployment.extensions/katib-manager created
service/katib-manager created
+ kubectl apply -f v1alpha3/pv
persistentvolume/katib-mysql created
persistentvolumeclaim/katib-mysql created
+ kubectl apply -f v1alpha3/db
deployment.extensions/katib-db created
secret/katib-db-secrets created
service/katib-db created
+ kubectl apply -f v1alpha3/ui
deployment.extensions/katib-ui created
clusterrole.rbac.authorization.k8s.io/katib-ui created
serviceaccount/katib-ui created
clusterrolebinding.rbac.authorization.k8s.io/katib-ui created
service/katib-ui created
+ kubectl apply -f tf-job
customresourcedefinition.apiextensions.k8s.io/tfjobs.kubeflow.org created
serviceaccount/tf-job-dashboard created
serviceaccount/tf-job-operator created
clusterrole.rbac.authorization.k8s.io/kubeflow-tfjobs-admin created
clusterrole.rbac.authorization.k8s.io/kubeflow-tfjobs-edit created
clusterrole.rbac.authorization.k8s.io/kubeflow-tfjobs-view created
clusterrole.rbac.authorization.k8s.io/tf-job-operator created
clusterrolebinding.rbac.authorization.k8s.io/tf-job-operator created
service/tf-job-operator created
deployment.apps/tf-job-operator created
+ kubectl apply -f pytorch
customresourcedefinition.apiextensions.k8s.io/pytorchjobs.kubeflow.org created
serviceaccount/pytorch-operator created
clusterrole.rbac.authorization.k8s.io/kubeflow-pytorchjobs-admin created
clusterrole.rbac.authorization.k8s.io/kubeflow-pytorchjobs-edit created
clusterrole.rbac.authorization.k8s.io/kubeflow-pytorchjobs-view created
clusterrole.rbac.authorization.k8s.io/pytorch-operator created
clusterrolebinding.rbac.authorization.k8s.io/pytorch-operator created
service/pytorch-operator created
deployment.apps/pytorch-operator created
```
 </details>
<p>Check that the Katib core components are installed and ready.</p>
<pre><code> kubectl -n kubeflow get pods
</code></pre>
<details>
<summary>
 Sample Output
 </summary>
<pre><code>NAME                                READY   STATUS    RESTARTS   AGE
katib-controller-7665868558-nfghw   1/1     Running   1          80s
katib-db-594756f779-dxttq           1/1     Running   0          81s
katib-manager-769b7bcbfb-7vvgx      1/1     Running   0          81s
katib-ui-854969c97-tl4wg            1/1     Running   0          79s
pytorch-operator-794899d49b-ww59g   1/1     Running   0          79s
tf-job-operator-7b589f5f5f-fpr2p    1/1     Running   0          80s
</code></pre>
</details>
<p><code>katib-controller</code>, <code>katib-manager</code>, <code>katib-db</code> and <code>katib-ui</code> are the core components of Katib.
We have also installed a <code>tf-job-operator</code> and <code>pytorch-operator</code> to be able to run TensorFlow Jobs and PyTorch Jobs.</p>
<p>You can access Katib UI <a href="http://localhost:31230/katib/">here</a>. If you are running on a non-Vagrant Kubernetes Cluster, you may need to use the Node IP for your VM or change the katib-ui service to use a LoadBalancer.</p>
<h1><a class="header" href="#hyperparameter-tuning-1" id="hyperparameter-tuning-1">Hyperparameter Tuning</a></h1>
<hr />
<p><em>This step takes about 10-15 mins to complete. Your Vagrant VM will likely be very busy at this time.
Please do not try to run multiple experiments on this simultaneously.</em></p>
<hr />
<p>Katib has an extensible architecture for <code>Suggestion</code> algorithms. Today we will look at some of the in-built models.</p>
<p>Let us start with the <code>random</code> algorithm using a TensorFlow Job example.</p>
<h1><a class="header" href="#random-search" id="random-search">Random Search</a></h1>
<p>Random search is a black box algorithm for searching for an optimal hyperparameter vector.
It assumes nothing about the model and trials can be run in parallel.</p>
<p>Random search selects points at random from the entire search space. </p>
<p><img src="katib/../images/random.png" alt="Random" /></p>
<p>Random search provides a good coverage for multiple hyperparameters in the search space.
If you want a generic baseline, it is always a good idea to start with a Random search.</p>
<p>Now let us create a random search experiment using Katib.</p>
<h3><a class="header" href="#experiment" id="experiment">Experiment</a></h3>
<p>Let us start by creating an experiment.</p>
<details>
<summary>
Random search experiment
</summary>
<pre><code class="language-yaml">apiVersion: &quot;kubeflow.org/v1alpha3&quot;
kind: Experiment
metadata:
  namespace: kubeflow
  name: tfjob-random
spec:
  parallelTrialCount: 3
  maxTrialCount: 12
  maxFailedTrialCount: 3
  objective:
    type: maximize
    goal: 0.99
    objectiveMetricName: accuracy_1
  algorithm:
    algorithmName: random
  metricsCollectorSpec:
    source:
      fileSystemPath:
        path: /train
        kind: Directory
    collector:
      kind: TensorFlowEvent
  parameters:
    - name: --learning_rate
      parameterType: double
      feasibleSpace:
        min: &quot;0.01&quot;
        max: &quot;0.05&quot;
    - name: --batch_size
      parameterType: int
      feasibleSpace:
        min: &quot;100&quot;
        max: &quot;200&quot;
  trialTemplate:
    goTemplate:
        rawTemplate: |-
          apiVersion: &quot;kubeflow.org/v1&quot;
          kind: TFJob
          metadata:
            name: {{.Trial}}
            namespace: {{.NameSpace}}
          spec:
           tfReplicaSpecs:
            Worker:
              replicas: 1
              restartPolicy: OnFailure
              template:
                spec:
                  containers:
                    - name: tensorflow
                      image: gcr.io/kubeflow-ci/tf-mnist-with-summaries:1.0
                      imagePullPolicy: IfNotPresent
                      command:
                        - &quot;python&quot;
                        - &quot;/var/tf_mnist/mnist_with_summaries.py&quot;
                        - &quot;--log_dir=/train/metrics&quot;
                        {{- with .HyperParameters}}
                        {{- range .}}
                        - &quot;{{.Name}}={{.Value}}&quot;
                        {{- end}}
                        {{- end}}
</code></pre>
</details>
<p><img src="katib/../images/experiment.png" alt="Experiment" /></p>
<pre><code class="language-console">cd $HOME/tutorial/examples/v1alpha3
kubectl apply -f tfjob-random.yaml
</code></pre>
<details>
<summary>
 Sample Output
 </summary>
experiment.kubeflow.org/tfjob-random created
</details>
<p>Check that the <code>Experiment</code> <strong>tfjob-random</strong> has started.</p>
<pre><code class="language-console">kubectl -n kubeflow get experiment
</code></pre>
<details>
<summary>
 Sample Output
 </summary>
NAME            STATUS    AGE
tfjob-random   Running   98s
</details>
<p>Check the details of the <code>Experiment</code> <strong>tfjob-random</strong></p>
<pre><code class="language-console">kubectl -n kubeflow get experiment tfjob-random -o json
</code></pre>
<details>
<summary>
 Sample Output
 </summary>
<pre><code class="language-json">{
    &quot;apiVersion&quot;: &quot;kubeflow.org/v1alpha3&quot;,
    &quot;kind&quot;: &quot;Experiment&quot;,
    &quot;metadata&quot;: {
        &quot;annotations&quot;: {
            &quot;kubectl.kubernetes.io/last-applied-configuration&quot;: &quot;{\&quot;apiVersion\&quot;:\&quot;kubeflow.org/v1alpha3\&quot;,\&quot;kind\&quot;:\&quot;Experiment\&quot;,\&quot;metadata\&quot;:{\&quot;annotations\&quot;:{},\&quot;name\&quot;:\&quot;tfjob-random\&quot;,\&quot;namespace\&quot;:\&quot;kubeflow\&quot;},\&quot;spec\&quot;:{\&quot;algorithm\&quot;:{\&quot;algorithmName\&quot;:\&quot;random\&quot;},\&quot;maxFailedTrialCount\&quot;:3,\&quot;maxTrialCount\&quot;:12,\&quot;metricsCollectorSpec\&quot;:{\&quot;collector\&quot;:{\&quot;kind\&quot;:\&quot;TensorFlowEvent\&quot;},\&quot;source\&quot;:{\&quot;fileSystemPath\&quot;:{\&quot;kind\&quot;:\&quot;Directory\&quot;,\&quot;path\&quot;:\&quot;/train\&quot;}}},\&quot;objective\&quot;:{\&quot;goal\&quot;:0.99,\&quot;objectiveMetricName\&quot;:\&quot;accuracy_1\&quot;,\&quot;type\&quot;:\&quot;maximize\&quot;},\&quot;parallelTrialCount\&quot;:3,\&quot;parameters\&quot;:[{\&quot;feasibleSpace\&quot;:{\&quot;max\&quot;:\&quot;0.05\&quot;,\&quot;min\&quot;:\&quot;0.01\&quot;},\&quot;name\&quot;:\&quot;--learning_rate\&quot;,\&quot;parameterType\&quot;:\&quot;double\&quot;},{\&quot;feasibleSpace\&quot;:{\&quot;max\&quot;:\&quot;200\&quot;,\&quot;min\&quot;:\&quot;100\&quot;},\&quot;name\&quot;:\&quot;--batch_size\&quot;,\&quot;parameterType\&quot;:\&quot;int\&quot;}],\&quot;trialTemplate\&quot;:{\&quot;goTemplate\&quot;:{\&quot;rawTemplate\&quot;:\&quot;apiVersion: \\\&quot;kubeflow.org/v1\\\&quot;\\nkind: TFJob\\nmetadata:\\n  name: {{.Trial}}\\n  namespace: {{.NameSpace}}\\nspec:\\n tfReplicaSpecs:\\n  Worker:\\n    replicas: 1 \\n    restartPolicy: OnFailure\\n    template:\\n      spec:\\n        containers:\\n          - name: tensorflow \\n            image: gcr.io/kubeflow-ci/tf-mnist-with-summaries:1.0\\n            imagePullPolicy: IfNotPresent\\n            command:\\n              - \\\&quot;python\\\&quot;\\n              - \\\&quot;/var/tf_mnist/mnist_with_summaries.py\\\&quot;\\n              - \\\&quot;--log_dir=/train/metrics\\\&quot;\\n              {{- with .HyperParameters}}\\n              {{- range .}}\\n              - \\\&quot;{{.Name}}={{.Value}}\\\&quot;\\n              {{- end}}\\n              {{- end}}\&quot;}}}}\n&quot;
        },
        &quot;creationTimestamp&quot;: &quot;2019-10-27T02:46:02Z&quot;,
        &quot;finalizers&quot;: [
            &quot;update-prometheus-metrics&quot;
        ],
        &quot;generation&quot;: 2,
        &quot;name&quot;: &quot;tfjob-random&quot;,
        &quot;namespace&quot;: &quot;kubeflow&quot;,
        &quot;resourceVersion&quot;: &quot;21979&quot;,
        &quot;selfLink&quot;: &quot;/apis/kubeflow.org/v1alpha3/namespaces/kubeflow/experiments/tfjob-random&quot;,
        &quot;uid&quot;: &quot;e9f888cb-f863-11e9-88ef-080027c5bc64&quot;
    },
    &quot;spec&quot;: {
        &quot;algorithm&quot;: {
            &quot;algorithmName&quot;: &quot;random&quot;,
            &quot;algorithmSettings&quot;: null
        },
        &quot;maxFailedTrialCount&quot;: 3,
        &quot;maxTrialCount&quot;: 12,
        &quot;metricsCollectorSpec&quot;: {
            &quot;collector&quot;: {
                &quot;kind&quot;: &quot;TensorFlowEvent&quot;
            },
            &quot;source&quot;: {
                &quot;fileSystemPath&quot;: {
                    &quot;kind&quot;: &quot;Directory&quot;,
                    &quot;path&quot;: &quot;/train&quot;
                }
            }
        },
        &quot;objective&quot;: {
            &quot;goal&quot;: 0.99,
            &quot;objectiveMetricName&quot;: &quot;accuracy_1&quot;,
            &quot;type&quot;: &quot;maximize&quot;
        },
        &quot;parallelTrialCount&quot;: 3,
        &quot;parameters&quot;: [
            {
                &quot;feasibleSpace&quot;: {
                    &quot;max&quot;: &quot;0.05&quot;,
                    &quot;min&quot;: &quot;0.01&quot;
                },
                &quot;name&quot;: &quot;--learning_rate&quot;,
                &quot;parameterType&quot;: &quot;double&quot;
            },
            {
                &quot;feasibleSpace&quot;: {
                    &quot;max&quot;: &quot;200&quot;,
                    &quot;min&quot;: &quot;100&quot;
                },
                &quot;name&quot;: &quot;--batch_size&quot;,
                &quot;parameterType&quot;: &quot;int&quot;
            }
        ],
        &quot;trialTemplate&quot;: {
            &quot;goTemplate&quot;: {
                &quot;rawTemplate&quot;: &quot;apiVersion: \&quot;kubeflow.org/v1\&quot;\nkind: TFJob\nmetadata:\n  name: {{.Trial}}\n  namespace: {{.NameSpace}}\nspec:\n tfReplicaSpecs:\n  Worker:\n    replicas: 1 \n    restartPolicy: OnFailure\n    template:\n      spec:\n        containers:\n          - name: tensorflow \n            image: gcr.io/kubeflow-ci/tf-mnist-with-summaries:1.0\n            imagePullPolicy: IfNotPresent\n            command:\n              - \&quot;python\&quot;\n              - \&quot;/var/tf_mnist/mnist_with_summaries.py\&quot;\n              - \&quot;--log_dir=/train/metrics\&quot;\n              {{- with .HyperParameters}}\n              {{- range .}}\n              - \&quot;{{.Name}}={{.Value}}\&quot;\n              {{- end}}\n              {{- end}}&quot;
            }
        }
    },
    &quot;status&quot;: {
        &quot;completionTime&quot;: null,
        &quot;conditions&quot;: [
            {
                &quot;lastTransitionTime&quot;: &quot;2019-10-27T02:46:02Z&quot;,
                &quot;lastUpdateTime&quot;: &quot;2019-10-27T02:46:02Z&quot;,
                &quot;message&quot;: &quot;Experiment is created&quot;,
                &quot;reason&quot;: &quot;ExperimentCreated&quot;,
                &quot;status&quot;: &quot;True&quot;,
                &quot;type&quot;: &quot;Created&quot;
            }
        ],
        &quot;currentOptimalTrial&quot;: {
            &quot;observation&quot;: {
                &quot;metrics&quot;: null
            },
            &quot;parameterAssignments&quot;: null
        },
        &quot;startTime&quot;: &quot;2019-10-27T02:46:02Z&quot;
    }
}
</code></pre>
</details>
<p>Under the hood, Katib controller is looping in a reconcile loop to satisfy this <code>Experiment</code> request.</p>
<p><img src="katib/../images/trials.png" alt="Trials" /></p>
<h3><a class="header" href="#suggestions" id="suggestions">Suggestions</a></h3>
<p>You can see Katib creating <code>Suggestions</code> using the <code>random</code> algorithm.</p>
<pre><code class="language-console">kubectl -n kubeflow  get suggestions tfjob-random -o yaml
</code></pre>
<details>
<summary>
 Sample Output - before suggestions are ready
 </summary>
<pre><code class="language-yaml">apiVersion: kubeflow.org/v1alpha3
kind: Suggestion
metadata:
  creationTimestamp: &quot;2019-10-27T02:57:58Z&quot;
  generation: 1
  name: tfjob-random
  namespace: kubeflow
  ownerReferences:
  - apiVersion: kubeflow.org/v1alpha3
    blockOwnerDeletion: true
    controller: true
    kind: Experiment
    name: tfjob-random
    uid: 94e07a51-f865-11e9-88ef-080027c5bc64
  resourceVersion: &quot;24296&quot;
  selfLink: /apis/kubeflow.org/v1alpha3/namespaces/kubeflow/suggestions/tfjob-random
  uid: 94e5930d-f865-11e9-88ef-080027c5bc64
spec:
  algorithmName: random
  requests: 3
status:
  conditions:
  - lastTransitionTime: &quot;2019-10-27T02:57:58Z&quot;
    lastUpdateTime: &quot;2019-10-27T02:57:58Z&quot;
    message: Suggestion is created
    reason: SuggestionCreated
    status: &quot;True&quot;
    type: Created
  - lastTransitionTime: &quot;2019-10-27T02:57:58Z&quot;
    lastUpdateTime: &quot;2019-10-27T02:57:58Z&quot;
    message: Deployment is not ready
    reason: DeploymentNotReady
    status: &quot;False&quot;
    type: DeploymentReady
  startTime: &quot;2019-10-27T02:57:58Z&quot;
</code></pre>
</details>
<p>We now have a <code>Suggestion</code> resource created. The Katib Suggestion Service takes control and generates a deployment to run the specified Suggestion.</p>
<p><img src="katib/../images/suggestion.png" alt="Suggestion" />
The suggestion service provides suggestions based on the current state of the system. On each new suggestion request, it reevaluates and provides the next best set of suggestions.</p>
<details>
<summary>
 Sample Output - after suggestions are ready
 </summary>
<pre><code class="language-yaml">apiVersion: v1
items:
- apiVersion: kubeflow.org/v1alpha3
  kind: Suggestion
  metadata:
    creationTimestamp: &quot;2019-10-27T02:57:58Z&quot;
    generation: 10
    name: tfjob-random
    namespace: kubeflow
    ownerReferences:
    - apiVersion: kubeflow.org/v1alpha3
      blockOwnerDeletion: true
      controller: true
      kind: Experiment
      name: tfjob-random
      uid: 94e07a51-f865-11e9-88ef-080027c5bc64
    resourceVersion: &quot;25675&quot;
    selfLink: /apis/kubeflow.org/v1alpha3/namespaces/kubeflow/suggestions/tfjob-random
    uid: 94e5930d-f865-11e9-88ef-080027c5bc64
  spec:
    algorithmName: random
    requests: 12
  status:
    conditions:
    - lastTransitionTime: &quot;2019-10-27T02:57:58Z&quot;
      lastUpdateTime: &quot;2019-10-27T02:57:58Z&quot;
      message: Suggestion is created
      reason: SuggestionCreated
      status: &quot;True&quot;
      type: Created
    - lastTransitionTime: &quot;2019-10-27T02:58:16Z&quot;
      lastUpdateTime: &quot;2019-10-27T02:58:16Z&quot;
      message: Deployment is ready
      reason: DeploymentReady
      status: &quot;True&quot;
      type: DeploymentReady
    - lastTransitionTime: &quot;2019-10-27T02:59:16Z&quot;
      lastUpdateTime: &quot;2019-10-27T02:59:16Z&quot;
      message: Suggestion is running
      reason: SuggestionRunning
      status: &quot;True&quot;
      type: Running
    startTime: &quot;2019-10-27T02:57:58Z&quot;
    suggestionCount: 12
    suggestions:
    - name: tfjob-random-npjpbgmd
      parameterAssignments:
      - name: --learning_rate
        value: &quot;0.03684477847537918&quot;
      - name: --batch_size
        value: &quot;112&quot;
    - name: tfjob-random-mmc8dqvq
      parameterAssignments:
      - name: --learning_rate
        value: &quot;0.010960280128777096&quot;
      - name: --batch_size
        value: &quot;126&quot;
    - name: tfjob-random-6h7229dt
      parameterAssignments:
      - name: --learning_rate
        value: &quot;0.011672960430260329&quot;
      - name: --batch_size
        value: &quot;181&quot;
    - name: tfjob-random-hfzrfh8j
      parameterAssignments:
      - name: --learning_rate
        value: &quot;0.03510831325099869&quot;
      - name: --batch_size
        value: &quot;156&quot;
    - name: tfjob-random-7kg9zhrt
      parameterAssignments:
      - name: --learning_rate
        value: &quot;0.02709470325001432&quot;
      - name: --batch_size
        value: &quot;157&quot;
    - name: tfjob-random-gng5qx9x
      parameterAssignments:
      - name: --learning_rate
        value: &quot;0.021854230935173045&quot;
      - name: --batch_size
        value: &quot;148&quot;
    - name: tfjob-random-5sfxkhmc
      parameterAssignments:
      - name: --learning_rate
        value: &quot;0.011053371330636894&quot;
      - name: --batch_size
        value: &quot;131&quot;
    - name: tfjob-random-7bzhkvvd
      parameterAssignments:
      - name: --learning_rate
        value: &quot;0.039025808494984444&quot;
      - name: --batch_size
        value: &quot;139&quot;
    - name: tfjob-random-xjm458qc
      parameterAssignments:
      - name: --learning_rate
        value: &quot;0.023093126743054533&quot;
      - name: --batch_size
        value: &quot;105&quot;
    - name: tfjob-random-zb89h929
      parameterAssignments:
      - name: --learning_rate
        value: &quot;0.017877859019641958&quot;
      - name: --batch_size
        value: &quot;192&quot;
    - name: tfjob-random-wqglhpqj
      parameterAssignments:
      - name: --learning_rate
        value: &quot;0.018670804338535255&quot;
      - name: --batch_size
        value: &quot;191&quot;
    - name: tfjob-random-484zhpzq
      parameterAssignments:
      - name: --learning_rate
        value: &quot;0.029127223437729596&quot;
      - name: --batch_size
        value: &quot;133&quot;
</code></pre>
</details>
<h3><a class="header" href="#trials" id="trials">Trials</a></h3>
<p>Once the suggestions are ready, Katib Trail controller is ready to run the trials.
Each <code>Trial</code> evaluates the performance for the suggested hyperparameter vector and records the performance in the metric collector.</p>
<p><img src="katib/../images/trials.png" alt="Suggestion" /></p>
<p>You can see Katib creating multiple <code>Trials</code>.</p>
<pre><code class="language-console">kubectl -n kubeflow get trials
</code></pre>
<details>
<summary>
 Sample Output
 </summary>
<p>NAME                    TYPE      STATUS   AGE
tfjob-random-5xq64qwz   Created   True     25s
tfjob-random-h9l2h54d   Created   True     25s
tfjob-random-pf5htw5f   Created   True     25s</p>
</details>
<p>Each trial starts a <code>TFJob</code> resource. </p>
<pre><code class="language-console">kubectl -n kubeflow get tfjobs
</code></pre>
<details>
<summary>
 Sample Output
 </summary>
<p>NAME                    TYPE      STATUS   AGE
tfjob-random-5xq64qwz   Created   True     25s
tfjob-random-h9l2h54d   Created   True     25s
tfjob-random-pf5htw5f   Created   True     25s</p>
</details>
<p>Each TFJob creates a <code>Worker</code> pod to run the trial.</p>
<pre><code class="language-console">kubectl -n kubeflow get po -l controller-name=tf-operator
</code></pre>
<details>
<summary>
 Sample Output
 </summary>
<pre><code>NAME                             READY   STATUS    RESTARTS   AGE
tfjob-random-484zhpzq-worker-0   2/2     Running   0          39s
tfjob-random-wqglhpqj-worker-0   2/2     Running   0          40s
tfjob-random-zb89h929-worker-0   2/2     Running   0          41s
</code></pre>
</details>
<h3><a class="header" href="#metric-collection" id="metric-collection">Metric Collection</a></h3>
<p>When we talked about the Kubernetes architecture we briefly mentioned how a user creates resources using the Kubernetes API server and how the Kubernetes API server stores this data in etcd.</p>
<p><img src="katib/../images/kubeapi-etcd.png" alt="kubeapi-etcd" /></p>
<p>In reality, there are several stages between the Kubernetes API server receiving a request before it is accepted.
In particular, there are two common extension points where external controllers can do additional tasks. These are mutating admission controllers and validating admission controllers.
Katib controller registers itself as both a mutating and validating controller.</p>
<p><img src="katib/../images/katib-webhook.png" alt="katib-webhook" /></p>
<p>You can see the webhooks as follows.</p>
<pre><code class="language-console">kubectl get MutatingWebhookConfiguration
</code></pre>
<details>
<summary>
 Sample Output
 </summary>
<pre><code>NAME                            CREATED AT
katib-mutating-webhook-config   2019-10-26T21:00:30Z
</code></pre>
</details>
<pre><code class="language-console">kubectl get ValidatingWebhookConfiguration
</code></pre>
<details>
<summary>
 Sample Output
 </summary>
<pre><code>NAME                              CREATED AT
katib-validating-webhook-config   2019-10-26T21:00:30Z
</code></pre>
</details>
<p>The mutating webhook looks at Katib configuration and injects a side car container to the <code>Trial</code> jobs/pods. You can see the configurations as follows.</p>
<pre><code class="language-console">kubectl -n kubeflow get cm katib-config -o yaml
</code></pre>
<details>
<summary>
 Sample Output
 </summary>
<pre><code class="language-yaml"> apiVersion: v1
data:
  metrics-collector-sidecar: |-
    {
      &quot;StdOut&quot;: {
              &quot;image&quot;: &quot;gcr.io/kubeflow-images-public/katib/v1alpha3/file-metrics-collector:v0.7.0&quot;
      },
      &quot;File&quot;: {
              &quot;image&quot;: &quot;gcr.io/kubeflow-images-public/katib/v1alpha3/file-metrics-collector:v0.7.0&quot;
      },
      &quot;TensorFlowEvent&quot;: {
              &quot;image&quot;: &quot;gcr.io/kubeflow-images-public/katib/v1alpha3/tfevent-metrics-collector:v0.7.0&quot;
      }
    }
  suggestion: |-
    {
      &quot;random&quot;: {
              &quot;image&quot;: &quot;gcr.io/kubeflow-images-public/katib/v1alpha3/suggestion-hyperopt:v0.7.0&quot;
      },
      &quot;grid&quot;: {
              &quot;image&quot;: &quot;gcr.io/kubeflow-images-public/katib/v1alpha3/suggestion-chocolate:v0.7.0&quot;
      },
      &quot;hyperband&quot;: {
              &quot;image&quot;: &quot;gcr.io/kubeflow-images-public/katib/v1alpha3/suggestion-hyperband:v0.7.0&quot;
      },
      &quot;bayesianoptimization&quot;: {
              &quot;image&quot;: &quot;gcr.io/kubeflow-images-public/katib/v1alpha3/suggestion-skopt:v0.7.0&quot;
      },
      &quot;tpe&quot;: {
              &quot;image&quot;: &quot;gcr.io/kubeflow-images-public/katib/v1alpha3/suggestion-hyperopt:v0.7.0&quot;
      },
      &quot;nasrl&quot;: {
              &quot;image&quot;: &quot;gcr.io/kubeflow-images-public/katib/v1alpha3/suggestion-nasrl:v0.7.0&quot;
      }
    }
kind: ConfigMap
</code></pre>
</details>
<p>We can see the metrics-collector container injected into the TFJob worker pod.</p>
<pre><code class="language-console">kubectl -n kubeflow describe  po -l controller-name=tf-operator
</code></pre>
<details>
<summary>
Sample Output
</summary>
<pre><code class="language-yaml">Name:               tfjob-random-g4p7jx5b-worker-0
Namespace:          kubeflow
Priority:           0
PriorityClassName:  &lt;none&gt;
Node:               katib/10.0.2.15
Start Time:         Tue, 29 Oct 2019 18:37:20 +0000
Labels:             controller-name=tf-operator
                    group-name=kubeflow.org
                    job-name=tfjob-random-g4p7jx5b
                    job-role=master
                    tf-job-name=tfjob-random-g4p7jx5b
                    tf-replica-index=0
                    tf-replica-type=worker
Annotations:        &lt;none&gt;
Status:             Pending
IP:
Controlled By:      TFJob/tfjob-random-g4p7jx5b
Containers:
  tensorflow:
    Container ID:
    Image:         gcr.io/kubeflow-ci/tf-mnist-with-summaries:1.0
    Image ID:
    Port:          2222/TCP
    Host Port:     0/TCP
    Command:
      python
      /var/tf_mnist/mnist_with_summaries.py
      --log_dir=/train/metrics
      --learning_rate=0.044867652686667765
      --batch_size=179
    State:          Waiting
      Reason:       ContainerCreating
    Ready:          False
    Restart Count:  0
    Environment:    &lt;none&gt;
    Mounts:
      /train from metrics-volume (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-mskhc (ro)
  metrics-collector:
    Container ID:
    Image:         gcr.io/kubeflow-images-public/katib/v1alpha3/tfevent-metrics-collector:v0.7.0
    Image ID:
    Port:          &lt;none&gt;
    Host Port:     &lt;none&gt;
    Args:
      -t
      tfjob-random-g4p7jx5b
      -m
      accuracy_1
      -s
      katib-manager.kubeflow:6789
      -path
      /train
    State:          Waiting
      Reason:       ContainerCreating
    Ready:          False
    Restart Count:  0
    Environment:    &lt;none&gt;
    Mounts:
      /train from metrics-volume (rw)
Conditions:
  Type              Status
  Initialized       True
  Ready             False
  ContainersReady   False
  PodScheduled      True
Volumes:
  default-token-mskhc:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-mskhc
    Optional:    false
  metrics-volume:
    Type:        EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:
    SizeLimit:   &lt;unset&gt;
QoS Class:       BestEffort
Node-Selectors:  &lt;none&gt;
Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
                 node.kubernetes.io/unreachable:NoExecute for 300s
Events:
  Type    Reason     Age   From               Message
  ----    ------     ----  ----               -------
  Normal  Scheduled  4s    default-scheduler  Successfully assigned kubeflow/tfjob-random-g4p7jx5b-worker-0 to katib
  Normal  Pulled     2s    kubelet, katib     Container image &quot;gcr.io/kubeflow-ci/tf-mnist-with-summaries:1.0&quot; already present on machine
  Normal  Created    2s    kubelet, katib     Created container tensorflow
  Normal  Started    1s    kubelet, katib     Started container tensorflow
  Normal  Pulled     1s    kubelet, katib     Container image &quot;gcr.io/kubeflow-images-public/katib/v1alpha3/tfevent-metrics-collector:v0.7.0&quot; already present on machine
  Normal  Created    1s    kubelet, katib     Created container metrics-collector
  Normal  Started    1s    kubelet, katib     Started container metrics-collector


Name:               tfjob-random-jcdvtfdf-worker-0
Namespace:          kubeflow
Priority:           0
PriorityClassName:  &lt;none&gt;
Node:               katib/10.0.2.15
Start Time:         Tue, 29 Oct 2019 18:35:44 +0000
Labels:             controller-name=tf-operator
                    group-name=kubeflow.org
                    job-name=tfjob-random-jcdvtfdf
                    job-role=master
                    tf-job-name=tfjob-random-jcdvtfdf
                    tf-replica-index=0
                    tf-replica-type=worker
Annotations:        &lt;none&gt;
Status:             Running
IP:                 192.168.0.231
Controlled By:      TFJob/tfjob-random-jcdvtfdf
Containers:
  tensorflow:
    Container ID:  docker://2792566751a57a6ab804621a9ec8b56e29ced44ddaceb6e395cd4fb8d7b0f7d6
    Image:         gcr.io/kubeflow-ci/tf-mnist-with-summaries:1.0
    Image ID:      docker-pullable://gcr.io/kubeflow-ci/tf-mnist-with-summaries@sha256:5c3181c3a97bc6f88fab204d4ac19ea12413b192953e21dc0ed07e7b821ddbe2
    Port:          2222/TCP
    Host Port:     0/TCP
    Command:
      python
      /var/tf_mnist/mnist_with_summaries.py
      --log_dir=/train/metrics
      --learning_rate=0.025430765523205827
      --batch_size=140
    State:          Running
      Started:      Tue, 29 Oct 2019 18:35:46 +0000
    Ready:          True
    Restart Count:  0
    Environment:    &lt;none&gt;
    Mounts:
      /train from metrics-volume (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-mskhc (ro)
  metrics-collector:
    Container ID:  docker://4109a92753bdfddb2aa9dd4f866fcddb068016e2a65b24a321ac0ac832fac48f
    Image:         gcr.io/kubeflow-images-public/katib/v1alpha3/tfevent-metrics-collector:v0.7.0
    Image ID:      docker-pullable://gcr.io/kubeflow-images-public/katib/v1alpha3/tfevent-metrics-collector@sha256:d7c8fa8147f99ebb563c4d59fc6c333f96684f1598cce2f7eae629a878671656
    Port:          &lt;none&gt;
    Host Port:     &lt;none&gt;
    Args:
      -t
      tfjob-random-jcdvtfdf
      -m
      accuracy_1
      -s
      katib-manager.kubeflow:6789
      -path
      /train
    State:          Running
      Started:      Tue, 29 Oct 2019 18:35:46 +0000
    Ready:          True
    Restart Count:  0
    Environment:    &lt;none&gt;
    Mounts:
      /train from metrics-volume (rw)
Conditions:
  Type              Status
  Initialized       True
  Ready             True
  ContainersReady   True
  PodScheduled      True
Volumes:
  default-token-mskhc:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-mskhc
    Optional:    false
  metrics-volume:
    Type:        EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:
    SizeLimit:   &lt;unset&gt;
QoS Class:       BestEffort
Node-Selectors:  &lt;none&gt;
Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
                 node.kubernetes.io/unreachable:NoExecute for 300s
Events:
  Type    Reason     Age   From               Message
  ----    ------     ----  ----               -------
  Normal  Scheduled  99s   default-scheduler  Successfully assigned kubeflow/tfjob-random-jcdvtfdf-worker-0 to katib
  Normal  Pulled     97s   kubelet, katib     Container image &quot;gcr.io/kubeflow-ci/tf-mnist-with-summaries:1.0&quot; already present on machine
  Normal  Created    97s   kubelet, katib     Created container tensorflow
  Normal  Started    97s   kubelet, katib     Started container tensorflow
  Normal  Pulled     97s   kubelet, katib     Container image &quot;gcr.io/kubeflow-images-public/katib/v1alpha3/tfevent-metrics-collector:v0.7.0&quot; already present on machine
  Normal  Created    97s   kubelet, katib     Created container metrics-collector
  Normal  Started    97s   kubelet, katib     Started container metrics-collector


Name:               tfjob-random-r66tzmjr-worker-0
Namespace:          kubeflow
Priority:           0
PriorityClassName:  &lt;none&gt;
Node:               katib/10.0.2.15
Start Time:         Tue, 29 Oct 2019 18:35:43 +0000
Labels:             controller-name=tf-operator
                    group-name=kubeflow.org
                    job-name=tfjob-random-r66tzmjr
                    job-role=master
                    tf-job-name=tfjob-random-r66tzmjr
                    tf-replica-index=0
                    tf-replica-type=worker
Annotations:        &lt;none&gt;
Status:             Running
IP:                 192.168.0.230
Controlled By:      TFJob/tfjob-random-r66tzmjr
Containers:
  tensorflow:
    Container ID:  docker://b3836fc16b83e82b3c3cad90472eeb079762f320270c834038d4a58f845f45b1
    Image:         gcr.io/kubeflow-ci/tf-mnist-with-summaries:1.0
    Image ID:      docker-pullable://gcr.io/kubeflow-ci/tf-mnist-with-summaries@sha256:5c3181c3a97bc6f88fab204d4ac19ea12413b192953e21dc0ed07e7b821ddbe2
    Port:          2222/TCP
    Host Port:     0/TCP
    Command:
      python
      /var/tf_mnist/mnist_with_summaries.py
      --log_dir=/train/metrics
      --learning_rate=0.04503686583590331
      --batch_size=120
    State:          Running
      Started:      Tue, 29 Oct 2019 18:35:45 +0000
    Ready:          True
    Restart Count:  0
    Environment:    &lt;none&gt;
    Mounts:
      /train from metrics-volume (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-mskhc (ro)
  metrics-collector:
    Container ID:  docker://a94b366df6c6e3e318be7b9a72e92c26e988167338aacae68498ef68662eb619
    Image:         gcr.io/kubeflow-images-public/katib/v1alpha3/tfevent-metrics-collector:v0.7.0
    Image ID:      docker-pullable://gcr.io/kubeflow-images-public/katib/v1alpha3/tfevent-metrics-collector@sha256:d7c8fa8147f99ebb563c4d59fc6c333f96684f1598cce2f7eae629a878671656
    Port:          &lt;none&gt;
    Host Port:     &lt;none&gt;
    Args:
      -t
      tfjob-random-r66tzmjr
      -m
      accuracy_1
      -s
      katib-manager.kubeflow:6789
      -path
      /train
    State:          Running
      Started:      Tue, 29 Oct 2019 18:35:45 +0000
    Ready:          True
    Restart Count:  0
    Environment:    &lt;none&gt;
    Mounts:
      /train from metrics-volume (rw)
Conditions:
  Type              Status
  Initialized       True
  Ready             True
  ContainersReady   True
  PodScheduled      True
Volumes:
  default-token-mskhc:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-mskhc
    Optional:    false
  metrics-volume:
    Type:        EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:
    SizeLimit:   &lt;unset&gt;
QoS Class:       BestEffort
Node-Selectors:  &lt;none&gt;
Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
                 node.kubernetes.io/unreachable:NoExecute for 300s
Events:
  Type    Reason     Age   From               Message
  ----    ------     ----  ----               -------
  Normal  Scheduled  100s  default-scheduler  Successfully assigned kubeflow/tfjob-random-r66tzmjr-worker-0 to katib
  Normal  Pulled     99s   kubelet, katib     Container image &quot;gcr.io/kubeflow-ci/tf-mnist-with-summaries:1.0&quot; already present on machine
  Normal  Created    99s   kubelet, katib     Created container tensorflow
  Normal  Started    98s   kubelet, katib     Started container tensorflow
  Normal  Pulled     98s   kubelet, katib     Container image &quot;gcr.io/kubeflow-images-public/katib/v1alpha3/tfevent-metrics-collector:v0.7.0&quot; already present on machine
  Normal  Created    98s   kubelet, katib     Created container metrics-collector
  Normal  Started    98s   kubelet, katib     Started container metrics-collector
</code></pre>
</details>
<h3><a class="header" href="#experiment-completion" id="experiment-completion">Experiment Completion</a></h3>
<p>Once the Trials created by Katib are complete, the Experiment enters a completed state.
Check the completion status of the <code>Experiment</code> <strong>tfjob-random</strong></p>
<pre><code class="language-console">kubectl -n kubeflow get experiment tfjob-random -o json
</code></pre>
<details>
<summary>
 Sample Output
 </summary>
</details>
<p>You can observe the status of this experiment under the <code>status</code> field of the output.</p>
<p>You can also see that Katib has cleaned up the <code>Trial</code> worker pods.</p>
<pre><code class="language-console">kubectl -n kubeflow get pods
</code></pre>
<details>
<summary>
 Sample Output
 </summary>
<pre><code> NAME                                    READY   STATUS    RESTARTS   AGE
katib-controller-7665868558-nfghw       1/1     Running   1          21m
katib-db-594756f779-dxttq               1/1     Running   0          21m
katib-manager-769b7bcbfb-7vvgx          1/1     Running   0          21m
katib-ui-854969c97-tl4wg                1/1     Running   0          21m
pytorch-operator-794899d49b-ww59g       1/1     Running   0          21m
tf-job-operator-7b589f5f5f-fpr2p        1/1     Running   0          21m
tfjob-example-random-6d68b59ccd-fcn8f   1/1     Running   0          15m
</code></pre>
</details>
<p>In summary all you need to know about is to create the <code>Experiment</code> specification. Katib magically does the rest for you.
<img src="katib/../images/summary.png" alt="Katib Magic" /></p>
<h1><a class="header" href="#grid-search" id="grid-search">Grid Search</a></h1>
<p>Grid search is also a black box algorithm similar to Random search. 
It assumes nothing about the model and each trial can be run in parallel.</p>
<p>Grid search does an exhaustive search over the entire search space. 
Ideally you want the search to be uniform across your entire search space. 
The following picture shows an example search with step size 10 for the batch size.</p>
<p><img src="katib/../images/grid.png" alt="Grid" /></p>
<p>However depending on the search space and the parameters you chose, the grid algorithm may end up not covering a lot of ground in one hyperparameter space. For example for the same example above, if you choose a step size of 3 instead of 10, you get the following coverage in 30 iterations.</p>
<p><img src="katib/../images/grid-bad.png" alt="Grid" /></p>
<p>So if you want a generic baseline, it is always a good idea to start with a Random search.</p>
<p>Now let us create a grid search experiment using Katib.</p>
<h3><a class="header" href="#experiment-1" id="experiment-1">Experiment</a></h3>
<p>Let us start by creating an experiment.</p>
<details>
<summary>
Grid search experiment
</summary>
<pre><code class="language-yaml">apiVersion: &quot;kubeflow.org/v1alpha3&quot;
kind: Experiment
metadata:
  namespace: kubeflow
  name: tfjob-grid
spec:
  parallelTrialCount: 3
  maxTrialCount: 12
  maxFailedTrialCount: 3
  objective:
    type: maximize
    goal: 0.99
    objectiveMetricName: accuracy_1
  algorithm:
    algorithmName: grid
  metricsCollectorSpec:
    source:
      fileSystemPath:
        path: /train
        kind: Directory
    collector:
      kind: TensorFlowEvent
  parameters:
    - name: --learning_rate
      parameterType: double
      feasibleSpace:
        min: &quot;0.01&quot;
        max: &quot;0.05&quot;
        step: &quot;0.001&quot;
    - name: --batch_size
      parameterType: int
      feasibleSpace:
        min: &quot;100&quot;
        max: &quot;200&quot;
        step: &quot;20&quot;
  trialTemplate:
    goTemplate:
        rawTemplate: |-
          apiVersion: &quot;kubeflow.org/v1&quot;
          kind: TFJob
          metadata:
            name: {{.Trial}}
            namespace: {{.NameSpace}}
          spec:
           tfReplicaSpecs:
            Worker:
              replicas: 1
              restartPolicy: OnFailure
              template:
                spec:
                  containers:
                    - name: tensorflow
                      image: gcr.io/kubeflow-ci/tf-mnist-with-summaries:1.0
                      imagePullPolicy: IfNotPresent
                      command:
                        - &quot;python&quot;
                        - &quot;/var/tf_mnist/mnist_with_summaries.py&quot;
                        - &quot;--log_dir=/train/metrics&quot;
                        {{- with .HyperParameters}}
                        {{- range .}}
                        - &quot;{{.Name}}={{.Value}}&quot;
                        {{- end}}
                        {{- end}}
</code></pre>
</details>
<p>There are two changes in this yaml compared to the random search. First we set <code>algorithmName: grid</code> instead of <code>algorithmName: random</code>. Second we set the step sizes using <code>step: &quot;0.001&quot;</code> and <code>step: &quot;20&quot;</code>.</p>
<p>Create this experiment as follows.</p>
<pre><code class="language-console">cd $HOME/tutorial/examples/v1alpha3
kubectl apply -f tfjob-grid.yaml
</code></pre>
<details>
<summary>
 Sample Output
 </summary>
<p>experiment.kubeflow.org/tfjob-grid created</p>
</details>
<p>Check that the <code>Experiment</code> <strong>tfjob-grid</strong> has started.</p>
<pre><code class="language-console">kubectl -n kubeflow get experiment
</code></pre>
<details>
<summary>
 Sample Output
 </summary>
NAME            STATUS    AGE
tfjob-grid   Running   98s
</details>
<p>Check the details of the <code>Experiment</code> <strong>tfjob-grid</strong></p>
<pre><code class="language-console">kubectl -n kubeflow get experiment tfjob-grid -o yaml
</code></pre>
<details>
<summary>
 Sample Output
 </summary>
<pre><code class="language-yaml">apiVersion: kubeflow.org/v1alpha3
kind: Experiment
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {&quot;apiVersion&quot;:&quot;kubeflow.org/v1alpha3&quot;,&quot;kind&quot;:&quot;Experiment&quot;,&quot;metadata&quot;:{&quot;annotations&quot;:{},&quot;name&quot;:&quot;tfjob-grid&quot;,&quot;namespace&quot;:&quot;kubeflow&quot;},&quot;spec&quot;:{&quot;algorithm&quot;:{&quot;algorithmName&quot;:&quot;grid&quot;},&quot;maxFailedTrialCount&quot;:3,&quot;maxTrialCount&quot;:12,&quot;metricsCollectorSpec&quot;:{&quot;collector&quot;:{&quot;kind&quot;:&quot;TensorFlowEvent&quot;},&quot;source&quot;:{&quot;fileSystemPath&quot;:{&quot;kind&quot;:&quot;Directory&quot;,&quot;path&quot;:&quot;/train&quot;}}},&quot;objective&quot;:{&quot;goal&quot;:0.99,&quot;objectiveMetricName&quot;:&quot;accuracy_1&quot;,&quot;type&quot;:&quot;maximize&quot;},&quot;parallelTrialCount&quot;:3,&quot;parameters&quot;:[{&quot;feasibleSpace&quot;:{&quot;max&quot;:&quot;0.05&quot;,&quot;min&quot;:&quot;0.01&quot;,&quot;step&quot;:&quot;0.001&quot;},&quot;name&quot;:&quot;--learning_rate&quot;,&quot;parameterType&quot;:&quot;double&quot;},{&quot;feasibleSpace&quot;:{&quot;max&quot;:&quot;200&quot;,&quot;min&quot;:&quot;100&quot;,&quot;step&quot;:&quot;1&quot;},&quot;name&quot;:&quot;--batch_size&quot;,&quot;parameterType&quot;:&quot;int&quot;}],&quot;trialTemplate&quot;:{&quot;goTemplate&quot;:{&quot;rawTemplate&quot;:&quot;apiVersion: \&quot;kubeflow.org/v1\&quot;\nkind: TFJob\nmetadata:\n  name: {{.Trial}}\n  namespace: {{.NameSpace}}\nspec:\n tfReplicaSpecs:\n  Worker:\n    replicas: 1 \n    restartPolicy: OnFailure\n    template:\n      spec:\n        containers:\n          - name: tensorflow \n            image: gcr.io/kubeflow-ci/tf-mnist-with-summaries:1.0\n            imagePullPolicy: IfNotPresent\n            command:\n              - \&quot;python\&quot;\n              - \&quot;/var/tf_mnist/mnist_with_summaries.py\&quot;\n              - \&quot;--log_dir=/train/metrics\&quot;\n              {{- with .HyperParameters}}\n              {{- range .}}\n              - \&quot;{{.Name}}={{.Value}}\&quot;\n              {{- end}}\n              {{- end}}&quot;}}}}
  creationTimestamp: &quot;2019-10-27T17:32:38Z&quot;
  finalizers:
  - update-prometheus-metrics
  generation: 2
  name: tfjob-grid
  namespace: kubeflow
  resourceVersion: &quot;153550&quot;
  selfLink: /apis/kubeflow.org/v1alpha3/namespaces/kubeflow/experiments/tfjob-grid
  uid: c5934b51-f8df-11e9-88ef-080027c5bc64
spec:
  algorithm:
    algorithmName: grid
    algorithmSettings: null
  maxFailedTrialCount: 3
  maxTrialCount: 12
  metricsCollectorSpec:
    collector:
      kind: TensorFlowEvent
    source:
      fileSystemPath:
        kind: Directory
        path: /train
  objective:
    goal: 0.99
    objectiveMetricName: accuracy_1
    type: maximize
  parallelTrialCount: 3
  parameters:
  - feasibleSpace:
      max: &quot;0.05&quot;
      min: &quot;0.01&quot;
      step: &quot;0.001&quot;
    name: --learning_rate
    parameterType: double
  - feasibleSpace:
      max: &quot;200&quot;
      min: &quot;100&quot;
      step: &quot;1&quot;
    name: --batch_size
    parameterType: int
  trialTemplate:
    goTemplate:
      rawTemplate: &quot;apiVersion: \&quot;kubeflow.org/v1\&quot;\nkind: TFJob\nmetadata:\n  name:
        {{.Trial}}\n  namespace: {{.NameSpace}}\nspec:\n tfReplicaSpecs:\n  Worker:\n
        \   replicas: 1 \n    restartPolicy: OnFailure\n    template:\n      spec:\n
        \       containers:\n          - name: tensorflow \n            image: gcr.io/kubeflow-ci/tf-mnist-with-summaries:1.0\n
        \           imagePullPolicy: IfNotPresent\n            command:\n              -
        \&quot;python\&quot;\n              - \&quot;/var/tf_mnist/mnist_with_summaries.py\&quot;\n              -
        \&quot;--log_dir=/train/metrics\&quot;\n              {{- with .HyperParameters}}\n
        \             {{- range .}}\n              - \&quot;{{.Name}}={{.Value}}\&quot;\n              {{-
        end}}\n              {{- end}}&quot;
status:
  completionTime: &quot;2019-10-27T17:42:37Z&quot;
  conditions:
  - lastTransitionTime: &quot;2019-10-27T17:32:38Z&quot;
    lastUpdateTime: &quot;2019-10-27T17:32:38Z&quot;
    message: Experiment is created
    reason: ExperimentCreated
    status: &quot;True&quot;
    type: Created
  - lastTransitionTime: &quot;2019-10-27T17:42:37Z&quot;
    lastUpdateTime: &quot;2019-10-27T17:42:37Z&quot;
    message: Experiment is running
    reason: ExperimentRunning
    status: &quot;False&quot;
    type: Running
  - lastTransitionTime: &quot;2019-10-27T17:42:37Z&quot;
    lastUpdateTime: &quot;2019-10-27T17:42:37Z&quot;
    message: Experiment has succeeded because max trial count has reached
    reason: ExperimentSucceeded
    status: &quot;True&quot;
    type: Succeeded
  currentOptimalTrial:
    observation:
      metrics:
      - name: accuracy_1
        value: 0.970499992371
    parameterAssignments:
    - name: --learning_rate
      value: &quot;0.01&quot;
    - name: --batch_size
      value: &quot;110&quot;
  startTime: &quot;2019-10-27T17:32:38Z&quot;
  trials: 12
  trialsSucceeded: 12
</code></pre>
</details>
<h1><a class="header" href="#bayesian-optimization" id="bayesian-optimization">Bayesian Optimization</a></h1>
<p>Model training is an expensive process and each time we want to evaluate a hyperparameter vector, we have to run this process.
This makes grid search very expensive as it is exponential in the number of hyperparameters. Random search may also need many iterations to get to a good hyperparameter vector as it is randomly trying out different options.
Before automatic hyperparameter tuning was wide spread, the common mechanism for finding a good set of hyperparameters was to use <code>Grad Student Descent</code> or <code>Intern Descent</code>. Human reasoning often follows a bayesian model, where we try out something and then iteratively pick what we think is a <code>good</code> next set of values to try. Systems in the real world often fit a probability distribution, like a normal distribution. Bayesian optimization models the hyperparameter vector performance as a distribution, often a Gaussian process. We then try to optimize the performance of this function. We also naturally make the trade off between exploration and exploitation. If the term paper is due tomorrow or if there is a release deadline, we may choose to optimize amongst the known best performing values. If we have a few months to try out different options, we may choose to try out a wider range of values.</p>
<p>Bayesian optimization follows a similar pattern with user configurable parameters to control the amount of exploration vs exploitation. Let us see how this works starting with an example based on the <a href="https://github.com/fmfn/BayesianOptimization">bayes_opt</a> package.</p>
<p>Let us assume that the unknown hyperparameter performance function for our hyperparameter of interest is as follows.
<img src="katib/../images/target.png" alt="Target" /></p>
<p>Initially we don't know anything about this function, so let us pick one hyperparameter vector at random and run the model training to evaluate the hyperparameter vector performance.</p>
<p><img src="katib/../images/run1.png" alt="Target" /></p>
<p>We can use expected improvement(EI) or Upper Confidence Bound(UCB) as the acquisition or utility function and pick a value that will optimize this. In this example we choose UCB as the utility function. UCB provides a way to configure the amount of exploration we want to allow. We choose the optimal value per the utility function and sample this value.</p>
<p><img src="katib/../images/run2.png" alt="Target" /></p>
<p>We repeat this process until we've reach the desired accuracy or we've exhausted our budget.</p>
<p><img src="katib/../images/run3.png" alt="Target" /></p>
<p>We can get to a globally optimal value pretty quickly</p>
<p><img src="katib/../images/run9.png" alt="Target" /></p>
<p>Here we picked an exploration constant of 5. If we repeated the same experiment with it set to 1, we can see that the algorithm does not explore too much and selects a local maximum instead of a global maximum, but also it converges much faster.</p>
<p><img src="katib/../images/local-optima.png" alt="Target" /></p>
<p>Depending on the available resources of computation and time, we can select different exploration/exploitation policies.</p>
<p>Now let us create a bayesian optimization experiment using Katib.</p>
<h3><a class="header" href="#experiment-2" id="experiment-2">Experiment</a></h3>
<p>Let us start by creating an experiment.</p>
<details>
<summary>
Random search experiment
</summary>
<pre><code class="language-yaml">apiVersion: &quot;kubeflow.org/v1alpha3&quot;
kind: Experiment
metadata:
  namespace: kubeflow
  name: tfjob-bayesian
spec:
  parallelTrialCount: 3
  maxTrialCount: 12
  maxFailedTrialCount: 3
  objective:
    type: maximize
    goal: 0.99
    objectiveMetricName: accuracy_1
  algorithm:
    algorithmName: bayesianoptimization
  metricsCollectorSpec:
    source:
      fileSystemPath:
        path: /train
        kind: Directory
    collector:
      kind: TensorFlowEvent
  parameters:
    - name: --learning_rate
      parameterType: double
      feasibleSpace:
        min: &quot;0.01&quot;
        max: &quot;0.05&quot;
    - name: --batch_size
      parameterType: int
      feasibleSpace:
        min: &quot;100&quot;
        max: &quot;200&quot;
  trialTemplate:
    goTemplate:
        rawTemplate: |-
          apiVersion: &quot;kubeflow.org/v1&quot;
          kind: TFJob
          metadata:
            name: {{.Trial}}
            namespace: {{.NameSpace}}
          spec:
           tfReplicaSpecs:
            Worker:
              replicas: 1
              restartPolicy: OnFailure
              template:
                spec:
                  containers:
                    - name: tensorflow
                      image: gcr.io/kubeflow-ci/tf-mnist-with-summaries:1.0
                      imagePullPolicy: IfNotPresent
                      command:
                        - &quot;python&quot;
                        - &quot;/var/tf_mnist/mnist_with_summaries.py&quot;
                        - &quot;--log_dir=/train/metrics&quot;
                        {{- with .HyperParameters}}
                        {{- range .}}
                        - &quot;{{.Name}}={{.Value}}&quot;
                        {{- end}}
                        {{- end}}

</code></pre>
</details>
<p>The only difference between random search and bayesian optimization specifications is the algorithm name <code>algorithmName: bayesianoptimization</code>. This is the primary advantage of using Katib. We can easily try different optimizations as they are added to Katib, without having to know too much about their implementation.</p>
<p>Let us create the experiment.</p>
<pre><code class="language-console">cd $HOME/tutorial/examples/v1alpha3
kubectl apply -f tfjob-bayesian.yaml
</code></pre>
<details>
<summary>
Sample Output
</summary>
<p>experiment.kubeflow.org/tfjob-bayesian created</p>
</details>
<p>Check the suggestions generated by the Bayesian optimizer and see how they differ from Grid/Random searches.</p>
<pre><code class="language-console">kubectl -n kubeflow get suggestions  tfjob-bayesian -o yaml
</code></pre>
<details>
<summary>
Sample Output
</summary>
<pre><code class="language-yaml">apiVersion: kubeflow.org/v1alpha3
kind: Suggestion
metadata:
  creationTimestamp: &quot;2019-10-27T19:18:49Z&quot;
  generation: 7
  name: tfjob-bayesian
  namespace: kubeflow
  ownerReferences:
  - apiVersion: kubeflow.org/v1alpha3
    blockOwnerDeletion: true
    controller: true
    kind: Experiment
    name: tfjob-bayesian
    uid: 9b175325-f8ee-11e9-88ef-080027c5bc64
  resourceVersion: &quot;168437&quot;
  selfLink: /apis/kubeflow.org/v1alpha3/namespaces/kubeflow/suggestions/tfjob-bayesian
  uid: 9b1d8453-f8ee-11e9-88ef-080027c5bc64
spec:
  algorithmName: bayesianoptimization
  requests: 9
status:
  conditions:
  - lastTransitionTime: &quot;2019-10-27T19:18:49Z&quot;
    lastUpdateTime: &quot;2019-10-27T19:18:49Z&quot;
    message: Suggestion is created
    reason: SuggestionCreated
    status: &quot;True&quot;
    type: Created
  - lastTransitionTime: &quot;2019-10-27T19:19:20Z&quot;
    lastUpdateTime: &quot;2019-10-27T19:19:20Z&quot;
    message: Deployment is ready
    reason: DeploymentReady
    status: &quot;True&quot;
    type: DeploymentReady
  - lastTransitionTime: &quot;2019-10-27T19:20:20Z&quot;
    lastUpdateTime: &quot;2019-10-27T19:20:20Z&quot;
    message: Suggestion is running
    reason: SuggestionRunning
    status: &quot;True&quot;
    type: Running
  startTime: &quot;2019-10-27T19:18:49Z&quot;
  suggestionCount: 9
  suggestions:
  - name: tfjob-bayesian-jtj6kc7w
    parameterAssignments:
    - name: --learning_rate
      value: &quot;0.011057901678989632&quot;
    - name: --batch_size
      value: &quot;159&quot;
  - name: tfjob-bayesian-grk2k47g
    parameterAssignments:
    - name: --learning_rate
      value: &quot;0.010248006471638945&quot;
    - name: --batch_size
      value: &quot;157&quot;
  - name: tfjob-bayesian-cvhmdgmg
    parameterAssignments:
    - name: --learning_rate
      value: &quot;0.048420638587223536&quot;
    - name: --batch_size
      value: &quot;178&quot;
  - name: tfjob-bayesian-4m2qn7dd
    parameterAssignments:
    - name: --learning_rate
      value: &quot;0.0227014807837709&quot;
    - name: --batch_size
      value: &quot;172&quot;
  - name: tfjob-bayesian-gbl5kns7
    parameterAssignments:
    - name: --learning_rate
      value: &quot;0.02417240356426028&quot;
    - name: --batch_size
      value: &quot;165&quot;
  - name: tfjob-bayesian-zxjrcbkj
    parameterAssignments:
    - name: --learning_rate
      value: &quot;0.04274224243794055&quot;
    - name: --batch_size
      value: &quot;165&quot;
  - name: tfjob-bayesian-zwvf497n
    parameterAssignments:
    - name: --learning_rate
      value: &quot;0.047036133061507786&quot;
    - name: --batch_size
      value: &quot;133&quot;
  - name: tfjob-bayesian-xf7vthlw
    parameterAssignments:
    - name: --learning_rate
      value: &quot;0.018676077504433782&quot;
    - name: --batch_size
      value: &quot;145&quot;
  - name: tfjob-bayesian-jhwvd5tn
    parameterAssignments:
    - name: --learning_rate
      value: &quot;0.022390829243915743&quot;
    - name: --batch_size
      value: &quot;174&quot;
</code></pre>
</details>
<p>Once the experiment is completed, we can check the optimal parameter values and the accuracy obtained.</p>
<pre><code class="language-console"> kubectl -n kubeflow get experiment  tfjob-bayesian -o yaml 
</code></pre>
<details>
 <summary>
 Sample Output
 </summary>
<pre><code class="language-yaml">apiVersion: kubeflow.org/v1alpha3
kind: Experiment
metadata:
 annotations:
   kubectl.kubernetes.io/last-applied-configuration: |
     {&quot;apiVersion&quot;:&quot;kubeflow.org/v1alpha3&quot;,&quot;kind&quot;:&quot;Experiment&quot;,&quot;metadata&quot;:{&quot;annotations&quot;:{},&quot;name&quot;:&quot;tfjob-bayesian&quot;,&quot;namespace&quot;:&quot;kubeflow&quot;},&quot;spec&quot;:{&quot;algorithm&quot;:{&quot;algorithmName&quot;:&quot;bayesianoptimization&quot;},&quot;maxFailedTrialCount&quot;:3,&quot;maxTrialCount&quot;:12,&quot;metricsCollectorSpec&quot;:{&quot;collector&quot;:{&quot;kind&quot;:&quot;TensorFlowEvent&quot;},&quot;source&quot;:{&quot;fileSystemPath&quot;:{&quot;kind&quot;:&quot;Directory&quot;,&quot;path&quot;:&quot;/train&quot;}}},&quot;objective&quot;:{&quot;goal&quot;:0.99,&quot;objectiveMetricName&quot;:&quot;accuracy_1&quot;,&quot;type&quot;:&quot;maximize&quot;},&quot;parallelTrialCount&quot;:3,&quot;parameters&quot;:[{&quot;feasibleSpace&quot;:{&quot;max&quot;:&quot;0.05&quot;,&quot;min&quot;:&quot;0.01&quot;},&quot;name&quot;:&quot;--learning_rate&quot;,&quot;parameterType&quot;:&quot;double&quot;},{&quot;feasibleSpace&quot;:{&quot;max&quot;:&quot;200&quot;,&quot;min&quot;:&quot;100&quot;},&quot;name&quot;:&quot;--batch_size&quot;,&quot;parameterType&quot;:&quot;int&quot;}],&quot;trialTemplate&quot;:{&quot;goTemplate&quot;:{&quot;rawTemplate&quot;:&quot;apiVersion: \&quot;kubeflow.org/v1\&quot;\nkind: TFJob\nmetadata:\n  name: {{.Trial}}\n  namespace: {{.NameSpace}}\nspec:\n tfReplicaSpecs:\n  Worker:\n    replicas: 1 \n    restartPolicy: OnFailure\n    template:\n      spec:\n        containers:\n          - name: tensorflow \n            image: gcr.io/kubeflow-ci/tf-mnist-with-summaries:1.0\n            imagePullPolicy: IfNotPresent\n            command:\n              - \&quot;python\&quot;\n              - \&quot;/var/tf_mnist/mnist_with_summaries.py\&quot;\n              - \&quot;--log_dir=/train/metrics\&quot;\n              {{- with .HyperParameters}}\n              {{- range .}}\n              - \&quot;{{.Name}}={{.Value}}\&quot;\n              {{- end}}\n              {{- end}}&quot;}}}}
 creationTimestamp: &quot;2019-10-27T19:18:49Z&quot;
 finalizers:
 - update-prometheus-metrics
 generation: 2
 name: tfjob-bayesian
 namespace: kubeflow
 resourceVersion: &quot;169359&quot;
 selfLink: /apis/kubeflow.org/v1alpha3/namespaces/kubeflow/experiments/tfjob-bayesian
 uid: 9b175325-f8ee-11e9-88ef-080027c5bc64
spec:
 algorithm:
   algorithmName: bayesianoptimization
   algorithmSettings: null
 maxFailedTrialCount: 3
 maxTrialCount: 12
 metricsCollectorSpec:
   collector:
     kind: TensorFlowEvent
   source:
     fileSystemPath:
       kind: Directory
       path: /train
 objective:
   goal: 0.99
   objectiveMetricName: accuracy_1
   type: maximize
 parallelTrialCount: 3
 parameters:
 - feasibleSpace:
     max: &quot;0.05&quot;
     min: &quot;0.01&quot;
   name: --learning_rate
   parameterType: double
 - feasibleSpace:
     max: &quot;200&quot;
     min: &quot;100&quot;
   name: --batch_size
   parameterType: int
 trialTemplate:
   goTemplate:
     rawTemplate: &quot;apiVersion: \&quot;kubeflow.org/v1\&quot;\nkind: TFJob\nmetadata:\n  name:
       {{.Trial}}\n  namespace: {{.NameSpace}}\nspec:\n tfReplicaSpecs:\n  Worker:\n
       \   replicas: 1 \n    restartPolicy: OnFailure\n    template:\n      spec:\n
       \       containers:\n          - name: tensorflow \n            image: gcr.io/kubeflow-ci/tf-mnist-with-summaries:1.0\n
       \           imagePullPolicy: IfNotPresent\n            command:\n              -
       \&quot;python\&quot;\n              - \&quot;/var/tf_mnist/mnist_with_summaries.py\&quot;\n              -
       \&quot;--log_dir=/train/metrics\&quot;\n              {{- with .HyperParameters}}\n
       \             {{- range .}}\n              - \&quot;{{.Name}}={{.Value}}\&quot;\n              {{-
       end}}\n              {{- end}}&quot;
status:
 completionTime: &quot;2019-10-27T19:29:45Z&quot;
 conditions:
 - lastTransitionTime: &quot;2019-10-27T19:18:49Z&quot;
   lastUpdateTime: &quot;2019-10-27T19:18:49Z&quot;
   message: Experiment is created
   reason: ExperimentCreated
   status: &quot;True&quot;
   type: Created
 - lastTransitionTime: &quot;2019-10-27T19:29:45Z&quot;
   lastUpdateTime: &quot;2019-10-27T19:29:45Z&quot;
   message: Experiment is running
   reason: ExperimentRunning
   status: &quot;False&quot;
   type: Running
 - lastTransitionTime: &quot;2019-10-27T19:29:45Z&quot;
   lastUpdateTime: &quot;2019-10-27T19:29:45Z&quot;
   message: Experiment has succeeded because max trial count has reached
   reason: ExperimentSucceeded
   status: &quot;True&quot;
   type: Succeeded
 currentOptimalTrial:
   observation:
     metrics:
     - name: accuracy_1
       value: 0.973200023174
   parameterAssignments:
   - name: --learning_rate
     value: &quot;0.010248006471638945&quot;
   - name: --batch_size
     value: &quot;157&quot;
 startTime: &quot;2019-10-27T19:18:49Z&quot;
 trials: 12
 trialsSucceeded: 12
</code></pre>
</details>
<p>In summary, different hyperparameter tuning algorithms have different characteristics and situations where they fit better.
Trying out multiple options is easy with Kubeflow/Katib.</p>
<p><img src="katib/../images/ui-random.png" alt="ui-random" /><img src="katib/../images/ui-grid.png" alt="ui-grid" /><img src="katib/../images/ui-bayesian.png" alt="ui-bayesian" /></p>
<h1><a class="header" href="#automatic-machine-learning" id="automatic-machine-learning">Automatic Machine Learning</a></h1>
<p>Applied Machine Learning is a highly iterative process. When you are training a neural network you have to make a lot of choices - like how many layers does the network have, how many hidden units should have, what is the learning rate, what is the activation function etc. It is almost impossible to correctly guess the correct values all these hyperparameters. Intuitions from one domain do not apply well to another domain.
When training a machine learning model, we want to optimize the in-sample error (Bias) and the out-of-sample error(variance). In the past we often saw that improving the bias resulted in over-fitting and high variance and vice versa.
With the rise of neural networks and big data, improving bias and variance together has become feasible. We can build larger neural networks to reduce bias and train them with more data to reduce variance. How ever this exacerbates the problem of selecting optimal hyperparameters and neural network architectures. This make automatic machine learning more desirable, but also feasible as we do not have to deal with the bias/variance trade off.</p>
<h1><a class="header" href="#kubeflow" id="kubeflow">Kubeflow</a></h1>
<h1><a class="header" href="#install-kubeflow" id="install-kubeflow">Install Kubeflow</a></h1>
<h3><a class="header" href="#download-kfctl" id="download-kfctl">Download kfctl</a></h3>
<details>
<summary>
Instructions for Mac OS X
</summary>
<pre><code class="language-console">curl -L -O https://github.com/kubeflow/kubeflow/releases/download/v0.7.0-rc.6/kfctl_v0.7.0-rc.5-7-gc66ebff3_darwin.tar.gz
tar xf kfctl_v0.7.0-rc.5-7-gc66ebff3_darwin.tar.gz
mv kfctl-darwin /usr/local/bin/kfctl
</code></pre>
</details>
<details>
<summary>
Instructions for Linux
</summary>
<pre><code class="language-console">curl -L -O https://github.com/kubeflow/kubeflow/releases/download/v0.7.0-rc.6/kfctl_v0.7.0-rc.5-7-gc66ebff3_linux.tar.gz
tar xf kfctl_v0.7.0-rc.5-7-gc66ebff3_linux.tar.gz
sudo mv kfctl /usr/local/bin/kfctl
</code></pre>
</details>
<h3><a class="header" href="#create-kubeflow-configuration" id="create-kubeflow-configuration">Create Kubeflow Configuration</a></h3>
<pre><code class="language-console">export KF_DIR=kubeflow-install
mkdir $KF_DIR
cd $KF_DIR

export CONFIG_FILE=https://raw.githubusercontent.com/kubeflow/manifests/master/kfdef/kfctl_k8s_istio.yaml
kfctl apply -V -f $CONFIG_FILE
</code></pre>
<p>Connect to Kubeflow Central Dashboard</p>
<pre><code class="language-console">export INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.spec.ports[?(@.name==&quot;http2&quot;)].nodePort}')
export INGRESS_HOST=$(kubectl get po -l istio=ingressgateway -n istio-system -o jsonpath={.items[0].status.hostIP})
echo http://$INGRESS_HOST:$INGRESS_PORT

</code></pre>
<h1><a class="header" href="#kubeflow-pipelines" id="kubeflow-pipelines">Kubeflow Pipelines</a></h1>
<p>Install a Python 3.x environment.</p>
<details>
<summary>
Instructions for Linux
</summary>
<p>Download pre-requisites</p>
<pre><code class="language-console">sudo apt-get update; sudo apt-get install -y curl bzip2
</code></pre>
<p>Install Miniconda</p>
<pre><code class="language-console">curl -L -O https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh
bash Miniconda3-latest-Linux-x86_64.sh
</code></pre>
<p>Restart your terminal session.</p>
<p>Verify that conda is added to your path.</p>
<pre><code class="language-console">which conda
</code></pre>
<details>
<summary>
Sample Output
</summary>
<p>/home/ubuntu/miniconda3/bin/conda</p>
</details>
</details>
<p>Create a new Python 3 environment</p>
<pre><code class="language-console">conda create --name mlpipeline python=3.7
</code></pre>
<p>Activate the new enviroment.</p>
<pre><code class="language-console">conda activate mlpipeline
</code></pre>
<p>Install Kubeflow Pipelines SDK</p>
<pre><code class="language-console">pip install \
    https://storage.googleapis.com/ml-pipeline/release/latest/kfp.tar.gz --upgrade
</code></pre>
<h1><a class="header" href="#cleanup" id="cleanup">Cleanup</a></h1>
<p>Deleting the vagrant VM</p>
<p>Go to the folder where you ran git clone in <a href="cleanup/../prereqs/download.html">Step 1.3</a>.</p>
<pre><code class="language-console">vagrant destroy
</code></pre>
<p>Get the list of Virtual Box VMs</p>
<pre><code class="language-console">vboxmanage list vms
</code></pre>
<p>Delete any unused VMs.</p>
<pre><code class="language-console">vboxmanage unregistervm &lt;vmid from the previous step&gt; --delete
</code></pre>
<h1><a class="header" href="#references" id="references">References</a></h1>
<p>https://github.com/kubeflow/katib
https://github.com/kubeflow/kubeflow
https://www.automl.org/book/</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                

                
            </nav>

        </div>

        

        

        

        
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        
        
        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
        
        

    </body>
</html>
